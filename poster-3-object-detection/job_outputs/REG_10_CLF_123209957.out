ðŸ”§ WORKING ON: Loading Train data
ðŸ”§ WORKING ON: Loading Validation data
ðŸ”§ WORKING ON: Loading Test data
â„¹ INFO: Using the entire dataset for training and validation.
ðŸ”§ WORKING ON: Training model
â„¹ INFO: Epoch 1/50 - Train Loss: 0.8138 (Cls: 0.3459, Reg: 0.4679) - Val Loss: 
0.4549 (Cls: 0.1153, Reg: 0.3396)
â„¹ INFO: Epoch 2/50 - Train Loss: 0.6402 (Cls: 0.2703, Reg: 0.3699) - Val Loss: 
0.4409 (Cls: 0.1195, Reg: 0.3214)
â„¹ INFO: Epoch 3/50 - Train Loss: 0.5903 (Cls: 0.2430, Reg: 0.3473) - Val Loss: 
0.4277 (Cls: 0.1097, Reg: 0.3180)
â„¹ INFO: Epoch 4/50 - Train Loss: 0.5538 (Cls: 0.2203, Reg: 0.3335) - Val Loss: 
0.4180 (Cls: 0.1040, Reg: 0.3140)
â„¹ INFO: Epoch 5/50 - Train Loss: 0.5231 (Cls: 0.2025, Reg: 0.3206) - Val Loss: 
0.4162 (Cls: 0.1118, Reg: 0.3045)
â„¹ INFO: Epoch 6/50 - Train Loss: 0.4972 (Cls: 0.1916, Reg: 0.3056) - Val Loss: 
0.4196 (Cls: 0.1151, Reg: 0.3045)
â„¹ INFO: Epoch 7/50 - Train Loss: 0.4793 (Cls: 0.1789, Reg: 0.3005) - Val Loss: 
0.3976 (Cls: 0.0947, Reg: 0.3029)
â„¹ INFO: Epoch 8/50 - Train Loss: 0.4534 (Cls: 0.1649, Reg: 0.2885) - Val Loss: 
0.4200 (Cls: 0.1072, Reg: 0.3128)
â„¹ INFO: Epoch 9/50 - Train Loss: 0.4329 (Cls: 0.1532, Reg: 0.2797) - Val Loss: 
0.4054 (Cls: 0.1038, Reg: 0.3017)
â„¹ INFO: Epoch 10/50 - Train Loss: 0.4014 (Cls: 0.1372, Reg: 0.2642) - Val Loss: 
0.4231 (Cls: 0.0962, Reg: 0.3269)
â„¹ INFO: Epoch 11/50 - Train Loss: 0.3873 (Cls: 0.1295, Reg: 0.2578) - Val Loss: 
0.4313 (Cls: 0.1332, Reg: 0.2981)
â„¹ INFO: Epoch 12/50 - Train Loss: 0.3707 (Cls: 0.1226, Reg: 0.2482) - Val Loss: 
0.3925 (Cls: 0.1003, Reg: 0.2922)
â„¹ INFO: Epoch 13/50 - Train Loss: 0.3582 (Cls: 0.1154, Reg: 0.2428) - Val Loss: 
0.4071 (Cls: 0.1205, Reg: 0.2866)
â„¹ INFO: Epoch 14/50 - Train Loss: 0.3363 (Cls: 0.1029, Reg: 0.2334) - Val Loss: 
0.4052 (Cls: 0.1091, Reg: 0.2961)
â„¹ INFO: Epoch 15/50 - Train Loss: 0.3305 (Cls: 0.0962, Reg: 0.2342) - Val Loss: 
0.4351 (Cls: 0.1435, Reg: 0.2915)
â„¹ INFO: Epoch 16/50 - Train Loss: 0.3166 (Cls: 0.0912, Reg: 0.2254) - Val Loss: 
0.4133 (Cls: 0.1166, Reg: 0.2967)
â„¹ INFO: Epoch 17/50 - Train Loss: 0.3052 (Cls: 0.0890, Reg: 0.2163) - Val Loss: 
0.4349 (Cls: 0.1238, Reg: 0.3112)
â„¹ INFO: Epoch 18/50 - Train Loss: 0.2916 (Cls: 0.0781, Reg: 0.2135) - Val Loss: 
0.4266 (Cls: 0.1169, Reg: 0.3097)
â„¹ INFO: Epoch 19/50 - Train Loss: 0.2879 (Cls: 0.0795, Reg: 0.2084) - Val Loss: 
0.4274 (Cls: 0.1291, Reg: 0.2982)
â„¹ INFO: Epoch 20/50 - Train Loss: 0.2790 (Cls: 0.0731, Reg: 0.2060) - Val Loss: 
0.4253 (Cls: 0.1321, Reg: 0.2932)
â„¹ INFO: Epoch 21/50 - Train Loss: 0.2708 (Cls: 0.0686, Reg: 0.2022) - Val Loss: 
0.4129 (Cls: 0.1259, Reg: 0.2870)
â„¹ INFO: Epoch 22/50 - Train Loss: 0.2608 (Cls: 0.0643, Reg: 0.1965) - Val Loss: 
0.4389 (Cls: 0.1516, Reg: 0.2874)
â„¹ INFO: Early stopping triggered.
ðŸ”§ WORKING ON: Visualizing predictions
Image ID: 565
Number of Proposals: 500
Predictions of potholes before NMS: 10
Predictions of potholes after NMS: 2
Image ID: 498
Number of Proposals: 500
Predictions of potholes before NMS: 0
Predictions of potholes after NMS: 0
Image ID: 11
Number of Proposals: 500
Predictions of potholes before NMS: 9
Predictions of potholes after NMS: 4
Image ID: 143
Number of Proposals: 500
Predictions of potholes before NMS: 0
Predictions of potholes after NMS: 0
Image ID: 65
Number of Proposals: 500
Predictions of potholes before NMS: 0
Predictions of potholes after NMS: 0
Image ID: 641
Number of Proposals: 500
Predictions of potholes before NMS: 0
Predictions of potholes after NMS: 0
Image ID: 627
Number of Proposals: 500
Predictions of potholes before NMS: 26
Predictions of potholes after NMS: 7
Image ID: 248
Number of Proposals: 500
Predictions of potholes before NMS: 0
Predictions of potholes after NMS: 0
Image ID: 611
Number of Proposals: 500
Predictions of potholes before NMS: 28
Predictions of potholes after NMS: 8
Image ID: 114
Number of Proposals: 500
Predictions of potholes before NMS: 8
Predictions of potholes after NMS: 2
Image Index: [196]
Number of Proposals: 12
Ground Truth Boxes: 3
Predictions Before NMS: 0
Predictions After NMS: 0
Image Index: [354]
Number of Proposals: 20
Ground Truth Boxes: 5
Predictions Before NMS: 3
Predictions After NMS: 1
Image Index: [77]
Number of Proposals: 24
Ground Truth Boxes: 6
Predictions Before NMS: 0
Predictions After NMS: 0
Image Index: [392]
Number of Proposals: 28
Ground Truth Boxes: 7
Predictions Before NMS: 0
Predictions After NMS: 0
Image Index: [88]
Number of Proposals: 40
Ground Truth Boxes: 10
Predictions Before NMS: 0
Predictions After NMS: 0
ðŸ”§ WORKING ON: Saving model
â„¹ INFO: Model state_dict saved to 
saved_models/model_state_dict_EXPERIMENT3Reg10.pth
â„¹ INFO: Entire model saved to saved_models/model_full_EXPERIMENT3Reg10.pth
ðŸ”§ WORKING ON: Evaluating model on Validation split
â„¹ INFO: Precision-Recall curve saved as 
figures/png/EXPERIMENT3Reg10/precision_recall_curve_val_EXPERIMENT3Reg10_2024111
9-165201.png and 
figures/svg/EXPERIMENT3Reg10/precision_recall_curve_val_EXPERIMENT3Reg10_2024111
9-165201.svg
precision: [0.         0.5        0.66666667 0.75       0.6        0.5
 0.42857143 0.5        0.55555556 0.5        0.54545455 0.58333333
 0.53846154 0.57142857 0.53333333 0.5625     0.52941176 0.55555556
 0.57894737 0.55       0.57142857 0.54545455 0.52173913 0.5
 0.48       0.5        0.51851852 0.53571429 0.55172414 0.53333333
 0.51612903 0.5        0.51515152 0.52941176 0.54285714 0.52777778
 0.54054054 0.52631579 0.53846154 0.525      0.51219512 0.5
 0.48837209 0.47727273 0.46666667 0.47826087 0.46808511 0.45833333
 0.46938776 0.46       0.47058824 0.46153846 0.45283019 0.44444444
 0.43636364 0.42857143 0.43859649 0.43103448 0.42372881 0.43333333
 0.44262295 0.43548387 0.42857143 0.421875   0.43076923 0.42424242
 0.43283582 0.42647059 0.42028986 0.41428571 0.4084507  0.41666667
 0.4109589  0.41891892 0.42666667 0.43421053 0.42857143 0.43589744
 0.43037975 0.425      0.41975309 0.41463415 0.40963855 0.4047619
 0.41176471 0.40697674 0.4137931  0.40909091 0.40449438 0.41111111
 0.40659341 0.40217391 0.40860215 0.40425532 0.4        0.39583333
 0.39175258 0.3877551  0.38383838 0.38       0.37623762 0.37254902
 0.36893204 0.36538462 0.36190476 0.35849057 0.35514019 0.35185185
 0.34862385 0.34545455 0.35135135 0.34821429 0.34513274 0.34210526
 0.34782609 0.34482759 0.34188034 0.33898305 0.33613445 0.33333333
 0.33057851 0.32786885 0.32520325 0.33064516 0.328      0.33333333
 0.33858268 0.3359375  0.33333333 0.33846154 0.33587786 0.33333333
 0.33082707 0.32835821 0.32592593 0.32352941 0.32116788 0.32608696
 0.32374101 0.32142857 0.32624113 0.32394366 0.32167832 0.31944444
 0.31724138 0.31506849 0.31292517 0.31081081 0.30872483 0.30666667
 0.30463576 0.30263158 0.30065359 0.2987013  0.29677419 0.29487179
 0.29299363 0.29113924 0.28930818 0.2875     0.28571429 0.28395062
 0.28834356 0.29268293 0.29090909 0.28915663 0.29341317 0.29166667
 0.28994083 0.28823529 0.28654971 0.28488372 0.28323699 0.28735632
 0.29142857 0.28977273 0.28813559 0.28651685 0.29050279 0.29444444
 0.29834254 0.3021978  0.30601093 0.30434783 0.3027027  0.30107527
 0.29946524 0.29787234 0.2962963  0.29473684 0.29842932 0.296875
 0.29533679 0.29381443 0.29230769 0.29081633 0.2893401  0.28787879
 0.28643216 0.285      0.28358209 0.28217822 0.28078818 0.27941176
 0.27804878 0.27669903 0.27536232 0.27403846 0.27272727 0.27619048
 0.27488152 0.27830189 0.27699531 0.27570093 0.2744186  0.27777778
 0.2764977  0.27981651 0.27853881 0.28181818 0.28054299 0.27927928
 0.27802691 0.27678571 0.27555556 0.27433628 0.27312775 0.27192982
 0.27510917 0.27391304 0.27705628 0.27586207 0.27467811 0.27777778
 0.28085106 0.27966102 0.27848101 0.27731092 0.28033473 0.27916667
 0.2780083  0.2768595  0.27572016 0.27459016 0.27346939 0.27235772
 0.27125506 0.27016129 0.26907631 0.268      0.26693227 0.26587302
 0.26482213 0.26771654 0.27058824 0.26953125 0.26848249 0.26744186
 0.26640927 0.26923077 0.27203065 0.27099237 0.26996198 0.26893939
 0.26792453 0.26691729 0.26966292 0.26865672 0.26765799 0.26666667
 0.26568266 0.26470588 0.26373626 0.26277372 0.26181818 0.26449275
 0.26353791 0.26258993 0.26164875 0.26071429 0.25978648 0.25886525
 0.25795053 0.25704225 0.25964912 0.25874126 0.25783972 0.25694444
 0.25605536 0.25517241 0.25429553 0.25342466 0.25255973 0.25510204
 0.25423729 0.25337838 0.25589226 0.25503356 0.25752508 0.25666667
 0.25581395 0.25496689 0.25412541 0.25328947 0.25245902 0.25163399
 0.25081433 0.25       0.24919094 0.2483871  0.24758842 0.24679487
 0.24600639 0.24840764 0.24761905 0.25       0.24921136 0.24842767
 0.2476489  0.246875   0.24610592 0.24534161 0.24458204 0.24382716
 0.24615385 0.24539877 0.24464832 0.24390244 0.24316109 0.24242424
 0.24169184 0.24096386 0.24324324 0.24251497 0.24179104 0.24404762
 0.24332344 0.24260355 0.24188791 0.24117647 0.24046921 0.24269006
 0.24489796 0.24418605 0.24347826 0.24566474 0.24495677 0.24425287
 0.24641834 0.24571429 0.24501425 0.24431818 0.24362606 0.24576271
 0.24507042 0.24438202 0.24369748 0.24301676 0.24512535 0.24444444
 0.24376731 0.24309392 0.24242424 0.24175824 0.24109589 0.24043716
 0.23978202 0.23913043 0.23848238 0.23783784 0.23719677 0.23924731
 0.2386059  0.24064171 0.24       0.2393617  0.23872679 0.23809524
 0.23746702 0.23684211 0.23622047 0.23560209 0.23498695 0.23697917
 0.23636364 0.23834197 0.2377261  0.2371134  0.23650386 0.23589744
 0.23785166 0.2372449  0.23664122 0.23857868 0.24050633 0.23989899
 0.23929471 0.24120603 0.2406015  0.2425     0.24189526 0.24129353
 0.24069479 0.24009901 0.23950617 0.23891626 0.23832924 0.2377451
 0.23716381 0.23902439 0.23844282 0.23786408 0.23728814 0.23913043
 0.23855422 0.23798077 0.23741007 0.23923445 0.23866348 0.23809524
 0.23752969 0.23696682 0.23640662 0.23584906 0.23764706 0.2370892
 0.23653396 0.23831776 0.23776224 0.23953488 0.2412993  0.24074074
 0.24018476 0.23963134 0.23908046 0.23853211 0.23798627 0.23744292
 0.23917995 0.23863636 0.24036281 0.24208145 0.24153499 0.24099099
 0.24269663 0.24215247 0.24161074 0.24107143 0.24053452 0.24222222
 0.24168514 0.24115044 0.2406181  0.24008811 0.23956044 0.23903509
 0.23851204 0.23799127 0.23747277 0.23913043 0.23861171 0.23809524
 0.23758099 0.23706897 0.23655914 0.2360515  0.23554604 0.23504274
 0.23454158 0.23404255 0.23354565 0.23516949 0.2346723  0.23417722
 0.23368421 0.23529412 0.23689727 0.23640167 0.23590814 0.23541667
 0.23492723 0.23443983 0.23395445 0.23347107 0.23298969 0.23251029
 0.23203285 0.23360656 0.23312883 0.23265306 0.23217923 0.23170732
 0.23123732 0.23076923 0.23030303 0.22983871 0.23138833 0.23092369
 0.23046092 0.23       0.23153693 0.2310757  0.2306163  0.23214286
 0.23168317 0.2312253  0.23076923 0.23228346 0.23182711 0.23137255
 0.23091977 0.23046875 0.23001949 0.22957198 0.22912621 0.22868217
 0.22823985 0.22779923]
recall: [0.         0.00847458 0.01694915 0.02542373 0.02542373 0.02542373
 0.02542373 0.03389831 0.04237288 0.04237288 0.05084746 0.05932203
 0.05932203 0.06779661 0.06779661 0.07627119 0.07627119 0.08474576
 0.09322034 0.09322034 0.10169492 0.10169492 0.10169492 0.10169492
 0.10169492 0.11016949 0.11864407 0.12711864 0.13559322 0.13559322
 0.13559322 0.13559322 0.1440678  0.15254237 0.16101695 0.16101695
 0.16949153 0.16949153 0.1779661  0.1779661  0.1779661  0.1779661
 0.1779661  0.1779661  0.1779661  0.18644068 0.18644068 0.18644068
 0.19491525 0.19491525 0.20338983 0.20338983 0.20338983 0.20338983
 0.20338983 0.20338983 0.21186441 0.21186441 0.21186441 0.22033898
 0.22881356 0.22881356 0.22881356 0.22881356 0.23728814 0.23728814
 0.24576271 0.24576271 0.24576271 0.24576271 0.24576271 0.25423729
 0.25423729 0.26271186 0.27118644 0.27966102 0.27966102 0.28813559
 0.28813559 0.28813559 0.28813559 0.28813559 0.28813559 0.28813559
 0.29661017 0.29661017 0.30508475 0.30508475 0.30508475 0.31355932
 0.31355932 0.31355932 0.3220339  0.3220339  0.3220339  0.3220339
 0.3220339  0.3220339  0.3220339  0.3220339  0.3220339  0.3220339
 0.3220339  0.3220339  0.3220339  0.3220339  0.3220339  0.3220339
 0.3220339  0.3220339  0.33050847 0.33050847 0.33050847 0.33050847
 0.33898305 0.33898305 0.33898305 0.33898305 0.33898305 0.33898305
 0.33898305 0.33898305 0.33898305 0.34745763 0.34745763 0.3559322
 0.36440678 0.36440678 0.36440678 0.37288136 0.37288136 0.37288136
 0.37288136 0.37288136 0.37288136 0.37288136 0.37288136 0.38135593
 0.38135593 0.38135593 0.38983051 0.38983051 0.38983051 0.38983051
 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051
 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051
 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051 0.38983051
 0.39830508 0.40677966 0.40677966 0.40677966 0.41525424 0.41525424
 0.41525424 0.41525424 0.41525424 0.41525424 0.41525424 0.42372881
 0.43220339 0.43220339 0.43220339 0.43220339 0.44067797 0.44915254
 0.45762712 0.46610169 0.47457627 0.47457627 0.47457627 0.47457627
 0.47457627 0.47457627 0.47457627 0.47457627 0.48305085 0.48305085
 0.48305085 0.48305085 0.48305085 0.48305085 0.48305085 0.48305085
 0.48305085 0.48305085 0.48305085 0.48305085 0.48305085 0.48305085
 0.48305085 0.48305085 0.48305085 0.48305085 0.48305085 0.49152542
 0.49152542 0.5        0.5        0.5        0.5        0.50847458
 0.50847458 0.51694915 0.51694915 0.52542373 0.52542373 0.52542373
 0.52542373 0.52542373 0.52542373 0.52542373 0.52542373 0.52542373
 0.53389831 0.53389831 0.54237288 0.54237288 0.54237288 0.55084746
 0.55932203 0.55932203 0.55932203 0.55932203 0.56779661 0.56779661
 0.56779661 0.56779661 0.56779661 0.56779661 0.56779661 0.56779661
 0.56779661 0.56779661 0.56779661 0.56779661 0.56779661 0.56779661
 0.56779661 0.57627119 0.58474576 0.58474576 0.58474576 0.58474576
 0.58474576 0.59322034 0.60169492 0.60169492 0.60169492 0.60169492
 0.60169492 0.60169492 0.61016949 0.61016949 0.61016949 0.61016949
 0.61016949 0.61016949 0.61016949 0.61016949 0.61016949 0.61864407
 0.61864407 0.61864407 0.61864407 0.61864407 0.61864407 0.61864407
 0.61864407 0.61864407 0.62711864 0.62711864 0.62711864 0.62711864
 0.62711864 0.62711864 0.62711864 0.62711864 0.62711864 0.63559322
 0.63559322 0.63559322 0.6440678  0.6440678  0.65254237 0.65254237
 0.65254237 0.65254237 0.65254237 0.65254237 0.65254237 0.65254237
 0.65254237 0.65254237 0.65254237 0.65254237 0.65254237 0.65254237
 0.65254237 0.66101695 0.66101695 0.66949153 0.66949153 0.66949153
 0.66949153 0.66949153 0.66949153 0.66949153 0.66949153 0.66949153
 0.6779661  0.6779661  0.6779661  0.6779661  0.6779661  0.6779661
 0.6779661  0.6779661  0.68644068 0.68644068 0.68644068 0.69491525
 0.69491525 0.69491525 0.69491525 0.69491525 0.69491525 0.70338983
 0.71186441 0.71186441 0.71186441 0.72033898 0.72033898 0.72033898
 0.72881356 0.72881356 0.72881356 0.72881356 0.72881356 0.73728814
 0.73728814 0.73728814 0.73728814 0.73728814 0.74576271 0.74576271
 0.74576271 0.74576271 0.74576271 0.74576271 0.74576271 0.74576271
 0.74576271 0.74576271 0.74576271 0.74576271 0.74576271 0.75423729
 0.75423729 0.76271186 0.76271186 0.76271186 0.76271186 0.76271186
 0.76271186 0.76271186 0.76271186 0.76271186 0.76271186 0.77118644
 0.77118644 0.77966102 0.77966102 0.77966102 0.77966102 0.77966102
 0.78813559 0.78813559 0.78813559 0.79661017 0.80508475 0.80508475
 0.80508475 0.81355932 0.81355932 0.8220339  0.8220339  0.8220339
 0.8220339  0.8220339  0.8220339  0.8220339  0.8220339  0.8220339
 0.8220339  0.83050847 0.83050847 0.83050847 0.83050847 0.83898305
 0.83898305 0.83898305 0.83898305 0.84745763 0.84745763 0.84745763
 0.84745763 0.84745763 0.84745763 0.84745763 0.8559322  0.8559322
 0.8559322  0.86440678 0.86440678 0.87288136 0.88135593 0.88135593
 0.88135593 0.88135593 0.88135593 0.88135593 0.88135593 0.88135593
 0.88983051 0.88983051 0.89830508 0.90677966 0.90677966 0.90677966
 0.91525424 0.91525424 0.91525424 0.91525424 0.91525424 0.92372881
 0.92372881 0.92372881 0.92372881 0.92372881 0.92372881 0.92372881
 0.92372881 0.92372881 0.92372881 0.93220339 0.93220339 0.93220339
 0.93220339 0.93220339 0.93220339 0.93220339 0.93220339 0.93220339
 0.93220339 0.93220339 0.93220339 0.94067797 0.94067797 0.94067797
 0.94067797 0.94915254 0.95762712 0.95762712 0.95762712 0.95762712
 0.95762712 0.95762712 0.95762712 0.95762712 0.95762712 0.95762712
 0.95762712 0.96610169 0.96610169 0.96610169 0.96610169 0.96610169
 0.96610169 0.96610169 0.96610169 0.96610169 0.97457627 0.97457627
 0.97457627 0.97457627 0.98305085 0.98305085 0.98305085 0.99152542
 0.99152542 0.99152542 0.99152542 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
â„¹ INFO: Experiment EXPERIMENT3Reg10 - mAP: 0.3499
ðŸ”§ WORKING ON: Evaluating model on Test split
â„¹ INFO: Precision-Recall curve saved as 
figures/png/EXPERIMENT3Reg10/precision_recall_curve_test_EXPERIMENT3Reg10_202411
19-165416.png and 
figures/svg/EXPERIMENT3Reg10/precision_recall_curve_test_EXPERIMENT3Reg10_202411
19-165416.svg
precision: [1.         0.5        0.66666667 0.5        0.6        0.66666667
 0.57142857 0.625      0.66666667 0.6        0.63636364 0.66666667
 0.69230769 0.71428571 0.73333333 0.75       0.70588235 0.66666667
 0.63157895 0.65       0.61904762 0.59090909 0.60869565 0.58333333
 0.6        0.61538462 0.59259259 0.57142857 0.55172414 0.53333333
 0.51612903 0.5        0.48484848 0.47058824 0.48571429 0.47222222
 0.45945946 0.47368421 0.46153846 0.475      0.46341463 0.45238095
 0.46511628 0.47727273 0.46666667 0.47826087 0.4893617  0.47916667
 0.46938776 0.46       0.45098039 0.46153846 0.45283019 0.44444444
 0.45454545 0.44642857 0.45614035 0.44827586 0.44067797 0.45
 0.44262295 0.43548387 0.42857143 0.4375     0.44615385 0.45454545
 0.46268657 0.45588235 0.46376812 0.45714286 0.46478873 0.47222222
 0.47945205 0.48648649 0.48       0.47368421 0.46753247 0.46153846
 0.4556962  0.45       0.44444444 0.43902439 0.43373494 0.42857143
 0.43529412 0.43023256 0.43678161 0.44318182 0.4494382  0.44444444
 0.43956044 0.44565217 0.4516129  0.45744681 0.45263158 0.45833333
 0.46391753 0.46938776 0.46464646 0.46       0.46534653 0.46078431
 0.45631068 0.45192308 0.44761905 0.44339623 0.43925234 0.44444444
 0.44954128 0.44545455 0.44144144 0.4375     0.43362832 0.42982456
 0.42608696 0.42241379 0.42735043 0.42372881 0.42857143 0.425
 0.4214876  0.41803279 0.41463415 0.41129032 0.416      0.42063492
 0.42519685 0.421875   0.41860465 0.41538462 0.41984733 0.42424242
 0.42857143 0.42537313 0.42222222 0.41911765 0.41605839 0.41304348
 0.41726619 0.42142857 0.42553191 0.42253521 0.42657343 0.43055556
 0.42758621 0.42465753 0.42176871 0.42567568 0.42281879 0.42
 0.41721854 0.41447368 0.41830065 0.41558442 0.41935484 0.42307692
 0.42038217 0.41772152 0.41509434 0.4125     0.40993789 0.40740741
 0.40490798 0.40243902 0.4        0.39759036 0.39520958 0.39880952
 0.3964497  0.4        0.40350877 0.40116279 0.40462428 0.40229885
 0.4        0.39772727 0.39548023 0.39325843 0.39106145 0.39444444
 0.39226519 0.39010989 0.38797814 0.38586957 0.38378378 0.38172043
 0.37967914 0.37765957 0.37566138 0.37894737 0.37696335 0.375
 0.37305699 0.37628866 0.37435897 0.37244898 0.37055838 0.36868687
 0.36683417 0.365      0.36318408 0.36138614 0.35960591 0.3627451
 0.36097561 0.3592233  0.36231884 0.36057692 0.35885167 0.35714286
 0.35545024 0.35377358 0.35211268 0.35046729 0.34883721 0.34722222
 0.34562212 0.34862385 0.34703196 0.35       0.34841629 0.34684685
 0.34529148 0.34821429 0.34666667 0.34513274 0.34801762 0.34649123
 0.34497817 0.34347826 0.34199134 0.34051724 0.33905579 0.33760684
 0.34042553 0.33898305 0.34177215 0.34033613 0.33891213 0.34166667
 0.34439834 0.34297521 0.34567901 0.3442623  0.34693878 0.34552846
 0.34412955 0.34274194 0.34136546 0.34       0.33864542 0.33730159
 0.33992095 0.33858268 0.3372549  0.3359375  0.33463035 0.33333333
 0.33204633 0.33076923 0.32950192 0.32824427 0.3269962  0.32575758
 0.32830189 0.32706767 0.32958801 0.32835821 0.32713755 0.32592593
 0.32472325 0.32720588 0.32600733 0.32846715 0.32727273 0.32608696
 0.32490975 0.32374101 0.32258065 0.325      0.32740214 0.32624113
 0.32508834 0.32394366 0.32280702 0.32167832 0.32055749 0.31944444
 0.3183391  0.32068966 0.31958763 0.31849315 0.31740614 0.31632653
 0.31525424 0.31418919 0.31313131 0.31208054 0.31103679 0.31
 0.3089701  0.30794702 0.30693069 0.30921053 0.30819672 0.31045752
 0.30944625 0.30844156 0.30744337 0.30645161 0.30546624 0.30769231
 0.30990415 0.31210191 0.31111111 0.31012658 0.30914826 0.3081761
 0.30721003 0.30625    0.30529595 0.30434783 0.30340557 0.30246914
 0.30153846 0.3006135  0.29969419 0.29878049 0.29787234 0.2969697
 0.29607251 0.29518072 0.29429429 0.29341317 0.29253731 0.29166667
 0.29080119 0.29289941 0.2920354  0.29117647 0.29032258 0.28947368
 0.28862974 0.2877907  0.28985507 0.28901734 0.28818444 0.28735632
 0.28653295 0.28571429 0.28490028 0.28409091 0.28328612 0.28248588
 0.28169014 0.28089888 0.28291317 0.2849162  0.28690808 0.28611111
 0.28531856 0.28453039 0.28374656 0.28296703 0.28219178 0.28415301
 0.28337875 0.2826087  0.28455285 0.28378378 0.28301887 0.28225806
 0.28150134 0.28074866 0.28266667 0.28191489 0.28116711 0.28042328
 0.27968338 0.28157895 0.2808399  0.28010471 0.27937337 0.27864583
 0.27792208 0.27720207 0.27906977 0.28092784 0.28277635 0.28205128
 0.28132992 0.28061224 0.27989822 0.27918782 0.28101266 0.28030303
 0.27959698 0.27889447 0.27819549 0.2775     0.27680798 0.2761194
 0.27543424 0.27475248 0.27407407 0.27339901 0.27272727 0.27205882
 0.27383863 0.27560976 0.27493917 0.27669903 0.27602906 0.27536232
 0.2746988  0.27403846 0.27338129 0.27272727 0.27207637 0.27142857
 0.27078385 0.27014218 0.26950355 0.26886792 0.27058824 0.26995305
 0.26932084 0.26869159 0.26806527 0.26744186 0.26682135 0.2662037
 0.26558891 0.26497696 0.26436782 0.26376147 0.26315789 0.26255708
 0.261959   0.26136364 0.26077098 0.260181   0.25959368 0.25900901
 0.26067416 0.26008969 0.25950783 0.25892857 0.25835189 0.25777778
 0.2594235  0.26106195 0.26048565 0.25991189 0.26153846 0.26096491
 0.26039387 0.26200873 0.26143791 0.26304348 0.26247289 0.26406926
 0.26349892 0.26293103 0.26236559 0.26180258 0.26124197 0.26068376
 0.26012793 0.26170213 0.2611465  0.26059322 0.26004228 0.25949367
 0.25894737 0.25840336 0.25786164 0.25732218 0.25887265 0.25833333
 0.25779626 0.25726141 0.25672878 0.25619835 0.2556701  0.25514403
 0.25462012 0.25409836 0.25562372 0.25510204 0.25458248 0.25406504
 0.2535497  0.25303644 0.25454545 0.25403226 0.2555332  0.25502008
 0.25651303 0.256      0.25548902 0.25498008 0.25447316 0.25396825
 0.25346535 0.25296443 0.25443787 0.25393701 0.25343811 0.25294118
 0.25244618 0.25195312 0.25146199 0.25097276 0.25048544 0.25
 0.24951644 0.24903475 0.24855491 0.24807692 0.24760077 0.24712644
 0.24665392 0.2480916  0.24761905 0.24714829 0.24667932 0.24621212
 0.24574669 0.24528302 0.24482109 0.2443609  0.24390244 0.24344569
 0.24485981 0.24440299 0.24394786 0.24349442 0.24304267 0.24259259
 0.24214418 0.24169742 0.2412523  0.24080882 0.24220183 0.24175824
 0.24131627 0.24087591 0.24043716 0.24       0.23956443 0.23913043
 0.23869801 0.2400722 ]
recall: [0.0075188  0.0075188  0.01503759 0.01503759 0.02255639 0.03007519
 0.03007519 0.03759398 0.04511278 0.04511278 0.05263158 0.06015038
 0.06766917 0.07518797 0.08270677 0.09022556 0.09022556 0.09022556
 0.09022556 0.09774436 0.09774436 0.09774436 0.10526316 0.10526316
 0.11278195 0.12030075 0.12030075 0.12030075 0.12030075 0.12030075
 0.12030075 0.12030075 0.12030075 0.12030075 0.12781955 0.12781955
 0.12781955 0.13533835 0.13533835 0.14285714 0.14285714 0.14285714
 0.15037594 0.15789474 0.15789474 0.16541353 0.17293233 0.17293233
 0.17293233 0.17293233 0.17293233 0.18045113 0.18045113 0.18045113
 0.18796992 0.18796992 0.19548872 0.19548872 0.19548872 0.20300752
 0.20300752 0.20300752 0.20300752 0.21052632 0.21804511 0.22556391
 0.23308271 0.23308271 0.2406015  0.2406015  0.2481203  0.2556391
 0.26315789 0.27067669 0.27067669 0.27067669 0.27067669 0.27067669
 0.27067669 0.27067669 0.27067669 0.27067669 0.27067669 0.27067669
 0.27819549 0.27819549 0.28571429 0.29323308 0.30075188 0.30075188
 0.30075188 0.30827068 0.31578947 0.32330827 0.32330827 0.33082707
 0.33834586 0.34586466 0.34586466 0.34586466 0.35338346 0.35338346
 0.35338346 0.35338346 0.35338346 0.35338346 0.35338346 0.36090226
 0.36842105 0.36842105 0.36842105 0.36842105 0.36842105 0.36842105
 0.36842105 0.36842105 0.37593985 0.37593985 0.38345865 0.38345865
 0.38345865 0.38345865 0.38345865 0.38345865 0.39097744 0.39849624
 0.40601504 0.40601504 0.40601504 0.40601504 0.41353383 0.42105263
 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143
 0.43609023 0.44360902 0.45112782 0.45112782 0.45864662 0.46616541
 0.46616541 0.46616541 0.46616541 0.47368421 0.47368421 0.47368421
 0.47368421 0.47368421 0.48120301 0.48120301 0.4887218  0.4962406
 0.4962406  0.4962406  0.4962406  0.4962406  0.4962406  0.4962406
 0.4962406  0.4962406  0.4962406  0.4962406  0.4962406  0.5037594
 0.5037594  0.5112782  0.51879699 0.51879699 0.52631579 0.52631579
 0.52631579 0.52631579 0.52631579 0.52631579 0.52631579 0.53383459
 0.53383459 0.53383459 0.53383459 0.53383459 0.53383459 0.53383459
 0.53383459 0.53383459 0.53383459 0.54135338 0.54135338 0.54135338
 0.54135338 0.54887218 0.54887218 0.54887218 0.54887218 0.54887218
 0.54887218 0.54887218 0.54887218 0.54887218 0.54887218 0.55639098
 0.55639098 0.55639098 0.56390977 0.56390977 0.56390977 0.56390977
 0.56390977 0.56390977 0.56390977 0.56390977 0.56390977 0.56390977
 0.56390977 0.57142857 0.57142857 0.57894737 0.57894737 0.57894737
 0.57894737 0.58646617 0.58646617 0.58646617 0.59398496 0.59398496
 0.59398496 0.59398496 0.59398496 0.59398496 0.59398496 0.59398496
 0.60150376 0.60150376 0.60902256 0.60902256 0.60902256 0.61654135
 0.62406015 0.62406015 0.63157895 0.63157895 0.63909774 0.63909774
 0.63909774 0.63909774 0.63909774 0.63909774 0.63909774 0.63909774
 0.64661654 0.64661654 0.64661654 0.64661654 0.64661654 0.64661654
 0.64661654 0.64661654 0.64661654 0.64661654 0.64661654 0.64661654
 0.65413534 0.65413534 0.66165414 0.66165414 0.66165414 0.66165414
 0.66165414 0.66917293 0.66917293 0.67669173 0.67669173 0.67669173
 0.67669173 0.67669173 0.67669173 0.68421053 0.69172932 0.69172932
 0.69172932 0.69172932 0.69172932 0.69172932 0.69172932 0.69172932
 0.69172932 0.69924812 0.69924812 0.69924812 0.69924812 0.69924812
 0.69924812 0.69924812 0.69924812 0.69924812 0.69924812 0.69924812
 0.69924812 0.69924812 0.69924812 0.70676692 0.70676692 0.71428571
 0.71428571 0.71428571 0.71428571 0.71428571 0.71428571 0.72180451
 0.72932331 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211
 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211
 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211
 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211 0.73684211
 0.73684211 0.7443609  0.7443609  0.7443609  0.7443609  0.7443609
 0.7443609  0.7443609  0.7518797  0.7518797  0.7518797  0.7518797
 0.7518797  0.7518797  0.7518797  0.7518797  0.7518797  0.7518797
 0.7518797  0.7518797  0.7593985  0.76691729 0.77443609 0.77443609
 0.77443609 0.77443609 0.77443609 0.77443609 0.77443609 0.78195489
 0.78195489 0.78195489 0.78947368 0.78947368 0.78947368 0.78947368
 0.78947368 0.78947368 0.79699248 0.79699248 0.79699248 0.79699248
 0.79699248 0.80451128 0.80451128 0.80451128 0.80451128 0.80451128
 0.80451128 0.80451128 0.81203008 0.81954887 0.82706767 0.82706767
 0.82706767 0.82706767 0.82706767 0.82706767 0.83458647 0.83458647
 0.83458647 0.83458647 0.83458647 0.83458647 0.83458647 0.83458647
 0.83458647 0.83458647 0.83458647 0.83458647 0.83458647 0.83458647
 0.84210526 0.84962406 0.84962406 0.85714286 0.85714286 0.85714286
 0.85714286 0.85714286 0.85714286 0.85714286 0.85714286 0.85714286
 0.85714286 0.85714286 0.85714286 0.85714286 0.86466165 0.86466165
 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165
 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165
 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165 0.86466165
 0.87218045 0.87218045 0.87218045 0.87218045 0.87218045 0.87218045
 0.87969925 0.88721805 0.88721805 0.88721805 0.89473684 0.89473684
 0.89473684 0.90225564 0.90225564 0.90977444 0.90977444 0.91729323
 0.91729323 0.91729323 0.91729323 0.91729323 0.91729323 0.91729323
 0.91729323 0.92481203 0.92481203 0.92481203 0.92481203 0.92481203
 0.92481203 0.92481203 0.92481203 0.92481203 0.93233083 0.93233083
 0.93233083 0.93233083 0.93233083 0.93233083 0.93233083 0.93233083
 0.93233083 0.93233083 0.93984962 0.93984962 0.93984962 0.93984962
 0.93984962 0.93984962 0.94736842 0.94736842 0.95488722 0.95488722
 0.96240602 0.96240602 0.96240602 0.96240602 0.96240602 0.96240602
 0.96240602 0.96240602 0.96992481 0.96992481 0.96992481 0.96992481
 0.96992481 0.96992481 0.96992481 0.96992481 0.96992481 0.96992481
 0.96992481 0.96992481 0.96992481 0.96992481 0.96992481 0.96992481
 0.96992481 0.97744361 0.97744361 0.97744361 0.97744361 0.97744361
 0.97744361 0.97744361 0.97744361 0.97744361 0.97744361 0.97744361
 0.98496241 0.98496241 0.98496241 0.98496241 0.98496241 0.98496241
 0.98496241 0.98496241 0.98496241 0.98496241 0.9924812  0.9924812
 0.9924812  0.9924812  0.9924812  0.9924812  0.9924812  0.9924812
 0.9924812  1.        ]
â„¹ INFO: Experiment EXPERIMENT3Reg10 - mAP: 0.4169
âœ… SUCCESS: Predictions saved to 'figures/'

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23209957: <REG_10_CLF_1> in cluster <dcc> Done

Job <REG_10_CLF_1> was submitted from host <n-62-20-1> by user <s240466> in cluster <dcc> at Tue Nov 19 15:48:42 2024
Job was executed on host(s) <4*n-62-18-8>, in queue <c02516>, as user <s240466> in cluster <dcc> at Tue Nov 19 15:48:43 2024
</zhome/26/8/209207> was used as the home directory.
</zhome/26/8/209207/02516-intro-to-dl-in-cv/poster-3-object-detection> was used as the working directory.
Started at Tue Nov 19 15:48:43 2024
Terminated at Tue Nov 19 16:54:19 2024
Results reported at Tue Nov 19 16:54:19 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -q c02516
#BSUB -n 4
#BSUB -gpu "num=1:mode=exclusive_process" 
#BSUB -J REG_10_CLF_1
#BSUB -R "span[hosts=1]"
#BSUB -R "rusage[mem=20GB]"
#BSUB -W 12:00
#BSUB -o job_outputs/REG_10_CLF_1%J.out
#BSUB -e job_outputs/REG_10_CLF_1%J.err

EXPERIMENT="EXPERIMENT3Reg10"
EPOCHS=50
LEARNING_RATE=1e-4
IOU_THRESHOLD=0.3
CONFIDENCE_THRESHOLD=0.5
WEIGHT_DECAY=1e-5
NUM_IMAGES=10

source ~/venv/project2_venv/bin/activate
#conda activate project-3

python main.py \
    --experiment_name $EXPERIMENT \
    --num_images $NUM_IMAGES \
    --learning_rate $LEARNING_RATE \
    --num_epochs $EPOCHS \
    --iou_threshold $IOU_THRESHOLD \
    --confidence_threshold $CONFIDENCE_THRESHOLD \
    --weight_decay $WEIGHT_DECAY \
    --cls_weight 1.0 \
    --reg_weight 10.0
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5109.00 sec.
    Max Memory :                                 5465 MB
    Average Memory :                             2985.96 MB
    Total Requested Memory :                     81920.00 MB
    Delta Memory :                               76455.00 MB
    Max Swap :                                   -
    Max Processes :                              10
    Max Threads :                                89
    Run time :                                   3991 sec.
    Turnaround time :                            3937 sec.

The output (if any) is above this job summary.



PS:

Read file <job_outputs/REG_10_CLF_123209957.err> for stderr output of this job.

